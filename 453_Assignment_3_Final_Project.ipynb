{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "453 - Assignment 3 Final Project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPLZ5t7KKk6OV6tmZDmEClm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/demelere/Text-Classification/blob/master/453_Assignment_3_Final_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80QrEWqaYLdh",
        "colab_type": "text"
      },
      "source": [
        "# 1. Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_AlqYyQsEDSK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "d5c88615-caba-4327-d464-525076f312be"
      },
      "source": [
        "# libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "qualitative_colors=sns.set_palette(\"Set3\",10)\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# word vectors\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "# model pipeline\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# models\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hn2_BBNWYVTy",
        "colab_type": "text"
      },
      "source": [
        "# 2. Data input and cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PiKJgWLRYdA4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('bbc-text.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCx9lkCLYjAG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 602
        },
        "outputId": "6885f035-54f5-4019-80f9-d6c19fe9ddc7"
      },
      "source": [
        "# Description of the dataset\n",
        "print('SHAPE OF DATASET: ', df.shape, '\\n\\nCOLUMNS IN DATASET: ', df.columns, '\\n\\nCATEGORIES: ', df.category.unique(), '\\n\\nDATA SAMPLE: \\n\\n', df.sample(n=5, random_state=0), '\\n\\n')\n",
        "\n",
        "# Plotting number of samples within each category\n",
        "print('NUMBER OF SAMPLES IN EACH CATEGORY: \\n')\n",
        "sns.countplot(x=df.category, order=df.category.value_counts().index,color=sns.set_palette(\"Paired\"))"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SHAPE OF DATASET:  (2225, 2) \n",
            "\n",
            "COLUMNS IN DATASET:  Index(['category', 'text'], dtype='object') \n",
            "\n",
            "CATEGORIES:  ['tech' 'business' 'sport' 'entertainment' 'politics'] \n",
            "\n",
            "DATA SAMPLE: \n",
            "\n",
            "       category                                               text\n",
            "384   politics  drive to  save  festive holidays efforts are b...\n",
            "1983     sport  officials respond in court row australian tenn...\n",
            "985      sport  cup holders man utd visit everton holders manc...\n",
            "1386     sport  adriano s chelsea link rejected adriano s agen...\n",
            "1294     sport  o driscoll/gregan lead aid stars ireland s bri... \n",
            "\n",
            "\n",
            "NUMBER OF SAMPLES IN EACH CATEGORY: \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fdd67910dd8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BhqJ2zTMlYVF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['category_id'] = df['category'].factorize()[0]\n",
        "category_id_df = df[['category', 'category_id']].drop_duplicates().sort_values('category_id')\n",
        "category_to_id = dict(category_id_df.values)\n",
        "id_to_category = dict(category_id_df[['category_id', 'category']].values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yy_82AFra0pi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "2ed1cd2d-d855-4088-f169-b8927095b801"
      },
      "source": [
        "# DATA CLEANING\n",
        "print('Data cleaning in progress...')\n",
        "\n",
        "# Tokenize\n",
        "df['text_clean'] = df['text'].apply(nltk.word_tokenize)\n",
        "print('Tokenization complete.')\n",
        "\n",
        "# Remove stop words\n",
        "stop_words=set(nltk.corpus.stopwords.words(\"english\"))\n",
        "df['text_clean'] = df['text_clean'].apply(lambda x: [item for item in x if item not in stop_words])\n",
        "print('Stop words removed.')\n",
        "\n",
        "# Remove numbers, punctuation and special characters (only keep words)\n",
        "regex = '[a-z]+'\n",
        "df['text_clean'] = df['text_clean'].apply(lambda x: [item for item in x if re.match(regex, item)])\n",
        "print('Numbers, punctuation and special characters removed.')\n",
        "\n",
        "# Lemmatization\n",
        "lem = nltk.stem.wordnet.WordNetLemmatizer()\n",
        "df['text_clean'] = df['text_clean'].apply(lambda x: [lem.lemmatize(item, pos='v') for item in x])\n",
        "print('Lemmatization complete.\\nData cleaning complete.\\n')"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data cleaning in progress...\n",
            "Tokenization complete.\n",
            "Stop words removed.\n",
            "Numbers, punctuation and special characters removed.\n",
            "Lemmatization complete.\n",
            "Data cleaning complete.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QU9St2tLgEhH",
        "colab_type": "text"
      },
      "source": [
        "# 3. Model training and evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxpPAsF8gLa2",
        "colab_type": "text"
      },
      "source": [
        "## 3.1 Classification using Word2Vec Vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIKZmoNEhqAJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vec_model = Word2Vec(df['text_clean'])\n",
        "w2v = dict(zip(vec_model.wv.index2word, vec_model.wv.syn0))\n",
        "\n",
        "class Vectorizer(object):\n",
        "    \n",
        "    def __init__(self, vec):\n",
        "        self.vec = vec\n",
        "        self.dim = len(vec.values())\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        return np.array([np.mean([self.vec[w] for w in words if w in self.vec] or [np.zeros(self.dim)], axis=0) for words in X])\n",
        "\n",
        "class Classifier(object):\n",
        "    \n",
        "    def __init__(self, model, param):\n",
        "        self.model = model\n",
        "        self.param = param\n",
        "        self.gs = GridSearchCV(self.model, self.param, cv=5, error_score=0, refit=True)        \n",
        "\n",
        "    def fit(self, X, y):        \n",
        "        return self.gs.fit(X, y)\n",
        "\n",
        "    def predict(self, X):\n",
        "        return self.gs.predict(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6N675SRdCJ3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf_models = {\n",
        "    'Logistic Regression': LogisticRegression(),\n",
        "    'Gradient Boosting': GradientBoostingClassifier(),\n",
        "    'Naive Bayes': GaussianNB(), \n",
        "    'SVC': SVC(),\n",
        "    'Perceptron': MLPClassifier()\n",
        "}\n",
        "\n",
        "clf_params = {\n",
        "    'Logistic Regression': { },\n",
        "    'Gradient Boosting': { 'min_samples_split': [2, 5] },\n",
        "    'Naive Bayes': { }, \n",
        "    'SVC': { 'kernel': ['linear', 'rbf'] },\n",
        "    'Perceptron': { 'activation': ['tanh', 'relu'] },\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_aiM-HBHdPBj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "35ff3e2d-0f58-447e-8df8-1b83de9628b8"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['category'], test_size=0.2, shuffle=True)\n",
        "\n",
        "for key in clf_models.keys():\n",
        "    \n",
        "    clf = Pipeline([('Word2Vec vectorizer', Vectorizer(w2v)), ('Classifier', Classifier(clf_models[key], clf_params[key]))])\n",
        "    \n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    \n",
        "    print(key, ':')\n",
        "    print(\"Accuracy: %1.3f \\tPrecision: %1.3f \\tRecall: %1.3f \\t\\tF1: %1.3f\\n\" % (accuracy_score(y_test, y_pred), precision_score(y_test, y_pred, average='macro'), recall_score(y_test, y_pred, average='macro'), f1_score(y_test, y_pred, average='macro')))"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Logistic Regression :\n",
            "Accuracy: 0.326 \tPrecision: 0.130 \tRecall: 0.278 \t\tF1: 0.177\n",
            "\n",
            "Gradient Boosting :\n",
            "Accuracy: 0.472 \tPrecision: 0.473 \tRecall: 0.461 \t\tF1: 0.459\n",
            "\n",
            "Naive Bayes :\n",
            "Accuracy: 0.353 \tPrecision: 0.413 \tRecall: 0.336 \t\tF1: 0.325\n",
            "\n",
            "SVC :\n",
            "Accuracy: 0.321 \tPrecision: 0.129 \tRecall: 0.274 \t\tF1: 0.175\n",
            "\n",
            "Perceptron :\n",
            "Accuracy: 0.351 \tPrecision: 0.142 \tRecall: 0.298 \t\tF1: 0.191\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OjzqfHiTgRVY",
        "colab_type": "text"
      },
      "source": [
        "## 3.2 Classification using TF-IDF Vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NHb1us4zGhD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Vectorize training and testing data\n",
        "def Vectorize(vec, X_train, X_test):    \n",
        "    \n",
        "    X_train_vec = vec.fit_transform(X_train)\n",
        "    X_test_vec = vec.transform(X_test)\n",
        "    \n",
        "    print('Vectorization complete.\\n')\n",
        "    \n",
        "    return X_train_vec, X_test_vec\n",
        "\n",
        "# Use multiple classifiers and grid search for prediction\n",
        "def ML_modeling(models, params, X_train, X_test, y_train, y_test):    \n",
        "    \n",
        "    if not set(models.keys()).issubset(set(params.keys())):\n",
        "        raise ValueError('Some estimators are missing parameters')\n",
        "\n",
        "    for key in models.keys():\n",
        "    \n",
        "        model = models[key]\n",
        "        param = params[key]\n",
        "        gs = GridSearchCV(model, param, cv=5, error_score=0, refit=True)\n",
        "        gs.fit(X_train, y_train)\n",
        "        y_pred = gs.predict(X_test)\n",
        "        \n",
        "        # Print scores for the classifier\n",
        "        print(key, ':', gs.best_params_)\n",
        "        print(\"Precision: %1.3f \\tRecall: %1.3f \\t\\tF1: %1.3f\\n\" % (precision_score(y_test, y_pred, average='macro'), recall_score(y_test, y_pred, average='macro'), f1_score(y_test, y_pred, average='macro')))\n",
        "    \n",
        "    return"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDRFmK3MzKA1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "models = {\n",
        "    'Logistic Regression': LogisticRegression(),\n",
        "    'SVC': SVC()\n",
        "}\n",
        "\n",
        "params = {\n",
        "    'Logistic Regression': { },\n",
        "    'SVC': { 'kernel': ['linear', 'rbf'] }\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbxLrRstzLXF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "91e52ea2-7d52-4485-f3a7-16d0d4bbf677"
      },
      "source": [
        "# Encode label categories to numbers\n",
        "enc = LabelEncoder()\n",
        "df['category'] = enc.fit_transform(df['category'])\n",
        "labels = list(enc.classes_)\n",
        "\n",
        "# Train-test split and vectorize\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['category'], test_size=0.2, shuffle=True)\n",
        "X_train_vec, X_test_vec = Vectorize(TfidfVectorizer(), X_train, X_test)\n",
        "\n",
        "ML_modeling(models, params, X_train_vec, X_test_vec, y_train, y_test)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vectorization complete.\n",
            "\n",
            "Logistic Regression : {}\n",
            "Precision: 0.976 \tRecall: 0.974 \t\tF1: 0.975\n",
            "\n",
            "SVC : {'kernel': 'linear'}\n",
            "Precision: 0.979 \tRecall: 0.981 \t\tF1: 0.980\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3SKD1bsy7cjp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "models = {\n",
        "    \n",
        "}\n",
        "\n",
        "params = {\n",
        "    \n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RDAnNvQ7R1W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        },
        "outputId": "dc1b716f-69b0-455e-bf4e-ebd47a5b4ff7"
      },
      "source": [
        "# Encode label categories to numbers\n",
        "enc = LabelEncoder()\n",
        "df['category'] = enc.fit_transform(df['category'])\n",
        "labels = list(enc.classes_)\n",
        "\n",
        "# Train-test split and vectorize\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['category'], test_size=0.2, shuffle=True)\n",
        "X_train_vec, X_test_vec = Vectorize(TfidfVectorizer(), X_train, X_test)\n",
        "\n",
        "ML_modeling(models, params, X_train_vec, X_test_vec, y_train, y_test)"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vectorization complete.\n",
            "\n",
            "Naive Bayes : {'alpha': 0.5, 'fit_prior': False}\n",
            "Precision: 0.955 \tRecall: 0.958 \t\tF1: 0.955\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-80-84060c2a7837>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mX_train_vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test_vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVectorize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mML_modeling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train_vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test_vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-77-6bbff548aac3>\u001b[0m in \u001b[0;36mML_modeling\u001b[0;34m(models, params, X_train, X_test, y_train, y_test)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mparam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrefit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    708\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 710\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1149\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1151\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    687\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 689\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1030\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1032\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1033\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    845\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    848\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    568\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 253\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 253\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    513\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    875\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 877\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    878\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    365\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDWZlMtxgU88",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# tfidf = TfidfVectorizer(sublinear_tf=True, min_df=5, norm='l2', encoding='latin-1', ngram_range=(1, 2), stop_words='english')\n",
        "\n",
        "# features = tfidf.fit_transform(df.text).toarray()\n",
        "# labels = df.category_id\n",
        "# features.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzQLjsJlibOE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# models = [\n",
        "#     LogisticRegression(random_state=0),\n",
        "#     # DecisionTreeClassifier(min_samples_split=[2, 5]),\n",
        "#     # RandomForestClassifier(n_estimators=200, max_depth=3, random_state=0),\n",
        "#     # MultinomialNB(),\n",
        "#     GradientBoostingClassifier(),\n",
        "#     GaussianNB(),\n",
        "#     SVC(kernel=['linear', 'rbf']),\n",
        "#     MLPClassifier(activation=['tanh','relu'])\n",
        "# ]\n",
        "\n",
        "# CV = 5\n",
        "# cv_df = pd.DataFrame(index=range(CV * len(models)))\n",
        "# entries = []\n",
        "# for model in models:\n",
        "#   model_name = model.__class__.__name__\n",
        "#   accuracies = cross_val_score(model, features, labels, scoring='accuracy', cv=CV)\n",
        "#   for fold_idx, accuracy in enumerate(accuracies):\n",
        "#     entries.append((model_name, fold_idx, accuracy))\n",
        "# cv_df = pd.DataFrame(entries, columns=['model_name', 'fold_idx', 'accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DT7lsOHppoe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}